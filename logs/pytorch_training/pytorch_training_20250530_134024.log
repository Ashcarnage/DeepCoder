2025-05-30 13:40:24,510 - AgenticTrainer - INFO - Training log: logs/pytorch_training/pytorch_training_20250530_134024.log
2025-05-30 13:40:24,538 - AgenticTrainer - INFO - Loading model: Qwen/Qwen2.5-1.5B-Instruct
2025-05-30 13:40:25,569 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-05-30 13:40:27,240 - AgenticTrainer - INFO - Model loaded with LoRA configuration
2025-05-30 13:40:27,241 - AgenticTrainer - INFO - Model dtype: torch.float16
2025-05-30 13:40:27,241 - AgenticTrainer - INFO - Device: cuda:0
2025-05-30 13:40:27,250 - AgenticTrainer - INFO - Training samples: 45
2025-05-30 13:40:27,251 - AgenticTrainer - INFO - Validation samples: 5
2025-05-30 13:40:27,253 - AgenticTrainer - INFO - Optimizer setup with lr=0.0002
2025-05-30 13:40:27,254 - AgenticTrainer - INFO - ðŸš€ Starting PyTorch Agentic Training with LoRA and SAD!
2025-05-30 13:40:27,254 - AgenticTrainer - INFO - ============================================================
2025-05-30 13:40:30,339 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:30,903 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 413 Payload Too Large"
2025-05-30 13:40:30,910 - AgenticTrainer - WARNING - Teacher model error: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01j5jb0kb9e7qv5erhdyh9wcdm` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 15066, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-05-30 13:40:31,217 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 413 Payload Too Large"
2025-05-30 13:40:31,218 - AgenticTrainer - WARNING - Teacher model error: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01j5jb0kb9e7qv5erhdyh9wcdm` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 8423, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-05-30 13:40:33,876 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:37,163 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:39,947 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:42,586 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:44,847 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:45,259 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:45,920 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:40:46,059 - AgenticTrainer - INFO - Step 10/200 | Loss: 8.9922 | LR: 1.99e-04 | Time: 18.8s
2025-05-30 13:40:46,210 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:40:46,211 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 32.000000 seconds
2025-05-30 13:41:21,000 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:41:21,799 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:41:24,652 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:41:24,921 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:41:24,922 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 19.000000 seconds
2025-05-30 13:41:46,319 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:41:46,602 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:41:46,609 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-05-30 13:42:03,899 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:07,043 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:07,493 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 413 Payload Too Large"
2025-05-30 13:42:07,494 - AgenticTrainer - WARNING - Teacher model error: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01j5jb0kb9e7qv5erhdyh9wcdm` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 10941, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-05-30 13:42:07,769 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:42:07,770 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-05-30 13:42:10,039 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:10,315 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:42:10,316 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-05-30 13:42:11,771 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:12,486 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:12,621 - AgenticTrainer - INFO - Step 20/200 | Loss: 7.4727 | LR: 1.95e-04 | Time: 105.4s
2025-05-30 13:42:12,745 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:42:12,746 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 14.000000 seconds
2025-05-30 13:42:27,032 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:29,117 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:29,230 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:42:29,231 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 11.000000 seconds
2025-05-30 13:42:42,334 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:42,460 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:42:42,461 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-05-30 13:42:46,285 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:42:46,387 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:42:46,388 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-05-30 13:43:00,490 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:00,500 - AgenticTrainer - INFO - ðŸ“Š Validation - Loss: nan | Distillation: nan | Agentic: 0.6799 | Reasoning: 0.3400
2025-05-30 13:43:00,657 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:43:00,658 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 17.000000 seconds
2025-05-30 13:43:17,986 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:18,832 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:19,142 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 413 Payload Too Large"
2025-05-30 13:43:19,143 - AgenticTrainer - WARNING - Teacher model error: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01j5jb0kb9e7qv5erhdyh9wcdm` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 10625, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-05-30 13:43:22,189 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:22,966 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:23,652 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:24,405 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:24,674 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:43:24,675 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 12.000000 seconds
2025-05-30 13:43:38,807 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:39,097 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:43:39,098 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-05-30 13:43:42,955 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:43,243 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:43:43,244 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-05-30 13:43:47,750 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:43:47,906 - AgenticTrainer - INFO - Step 30/200 | Loss: 5.8359 | LR: 1.89e-04 | Time: 200.7s
2025-05-30 13:43:48,029 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:43:48,031 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 18.000000 seconds
2025-05-30 13:44:08,451 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:44:08,738 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:44:08,739 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 57.000000 seconds
2025-05-30 13:45:08,378 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:11,294 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:16,664 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:19,506 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:19,799 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 413 Payload Too Large"
2025-05-30 13:45:19,810 - AgenticTrainer - WARNING - Teacher model error: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01j5jb0kb9e7qv5erhdyh9wcdm` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 9749, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-05-30 13:45:23,334 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:23,972 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:26,708 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:27,392 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:27,525 - AgenticTrainer - INFO - Step 40/200 | Loss: 4.6211 | LR: 1.81e-04 | Time: 300.3s
2025-05-30 13:45:27,650 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:45:27,651 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 5.000000 seconds
2025-05-30 13:45:32,746 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:45:32,747 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 4.000000 seconds
2025-05-30 13:45:39,409 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:39,539 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:45:39,540 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-05-30 13:45:41,912 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:42,079 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:45:42,081 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-05-30 13:45:54,753 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:54,948 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:45:54,949 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds
2025-05-30 13:45:56,428 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:45:56,554 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:45:56,556 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds
2025-05-30 13:46:07,688 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:46:07,698 - AgenticTrainer - INFO - ðŸŽ¯ New best validation loss: 5.5438
2025-05-30 13:46:07,699 - AgenticTrainer - INFO - ðŸ“Š Validation - Loss: 5.5438 | Distillation: 7.6414 | Agentic: 0.7999 | Reasoning: 0.3400
2025-05-30 13:46:08,763 - AgenticTrainer - INFO - Checkpoint saved: checkpoints/pytorch_training/checkpoint_step_40
2025-05-30 13:46:10,186 - AgenticTrainer - INFO - Training plot saved: plots/training/training_progress_step_40.html
2025-05-30 13:46:10,847 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-30 13:46:11,134 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-30 13:46:11,135 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 59.000000 seconds
